{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from csbdeep.io import load_training_data\n",
    "from csbdeep.utils import axes_dict, plot_some\n",
    "import matplotlib.pyplot as plt\n",
    "from actin_tubules_sim.models import DFCAN\n",
    "from actin_tubules_sim.loss import mse_ssim\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/Users/vkapoor/Downloads/Microtubules'\n",
    "train_data_file = f'{root_dir}/Train/SR/microtubule_sr_training_data.npz'\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training images:\t 495\n",
      "number of validation images:\t 55\n",
      "image size (3D):\t\t (9, 128, 128)\n",
      "axes:\t\t\t\t SZYXC\n",
      "channels in / out:\t\t 1 / 1\n"
     ]
    }
   ],
   "source": [
    "(X,Y), (X_val,Y_val), axes = load_training_data(train_data_file, validation_split=0.1, verbose=True)\n",
    "\n",
    "c = axes_dict(axes)['C']\n",
    "n_channel_in, n_channel_out = X.shape[c], Y.shape[c]\n",
    "X = tf.squeeze(X, axis=-1)\n",
    "X_val = tf.squeeze(X_val, axis=-1)\n",
    "Y = tf.squeeze(Y, axis=-1)\n",
    "Y_val = tf.squeeze(Y_val, axis=-1)\n",
    "X = tf.transpose(X, perm=[0, 2, 3, 1])\n",
    "X_val = tf.transpose(X_val, perm=[0, 2, 3, 1])\n",
    "\n",
    "Y = tf.transpose(Y, perm=[0, 2, 3, 1])\n",
    "\n",
    "Y_val = tf.transpose(Y_val, perm=[0, 2, 3, 1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([495, 128, 128, 9]),\n",
       " TensorShape([495, 256, 256, 1]),\n",
       " TensorShape([55, 128, 128, 9]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,Y.shape,X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plot_some(tf.transpose(X_val[:5], perm=[0, 3, 1, 2]),Y_val[:5])\n",
    "plt.suptitle('5 example validation patches (top row: source, bottom row: target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_lr = 1e-4\n",
    "batch_size = 3\n",
    "epochs = 10\n",
    "beta_1=0.9\n",
    "beta_2=0.999\n",
    "scale_gt = 2.0\n",
    "\n",
    "total_data,  height, width, channels= X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainingmodel = DFCAN((height, width, channels), scale=scale_gt)\n",
    "optimizer = Adam(learning_rate=init_lr, beta_1=beta_1, beta_2=beta_2)\n",
    "Trainingmodel.compile(loss=mse_ssim, optimizer=optimizer)\n",
    "Trainingmodel.summary()\n",
    "\n",
    "tensorboard_callback = callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "lrate = callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1, patience=4, verbose=1)\n",
    "hrate = callbacks.History()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Training the model will likely take some time. We recommend to monitor the progress with [TensorBoard](https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard), which allows you to inspect the losses during training.\n",
    "\n",
    "You can start TensorBoard from the current working directory with `tensorboard --logdir=.` Then connect to http://localhost:6006/ with your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Tensor(\"model_4/lambda_413/mul_1:0\", shape=(3, 128, 128, 256), dtype=float32),2.0\n",
      "Tensor(\"model_4/lambda_413/mul_1:0\", shape=(3, 128, 128, 256), dtype=float32),2.0\n",
      "165/165 [==============================] - ETA: 0s - loss: 0.0715Tensor(\"model_4/lambda_413/mul_1:0\", shape=(None, 128, 128, 256), dtype=float32),2.0\n",
      "165/165 [==============================] - 1025s 6s/step - loss: 0.0715 - val_loss: 0.0424 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "165/165 [==============================] - 1095s 7s/step - loss: 0.0317 - val_loss: 0.0293 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "165/165 [==============================] - 1039s 6s/step - loss: 0.0254 - val_loss: 0.0271 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "  4/165 [..............................] - ETA: 16:39 - loss: 0.0180"
     ]
    }
   ],
   "source": [
    "Trainingmodel.fit(X, Y, batch_size=batch_size,\n",
    "                               epochs=epochs, validation_data=(X_val, Y_val), shuffle=True,\n",
    "                               callbacks=[lrate, hrate, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Trainingmodel.save(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kapoorlabsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
